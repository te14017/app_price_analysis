{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 features dropped\n",
      "(24768, 16) X_all\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../preprocess/')\n",
    "sys.path.append('../evaluate/')\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer, LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV as RSCV\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "import cleanup\n",
    "import prepare\n",
    "import evaluate\n",
    "\n",
    "# n_jobs\n",
    "NJ = -1\n",
    "\n",
    "# scoring\n",
    "SCORE = 'f1_weighted'\n",
    "\n",
    "# n_splits\n",
    "STRAT_SPLITS = 3\n",
    "\n",
    "# n_iter\n",
    "SEARCH_ITER = 3\n",
    "\n",
    "data = pd.read_csv(\"data_transformed.csv\")\n",
    "cleanup.dropFeatures(data, ['appId', 'similarApps'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "######################################\n",
    "# Load preprocessed Data\n",
    "#\n",
    "X_all, y_all = data.drop('price', axis=1), data['price']\n",
    "\n",
    "print(\"{0} X_all\".format(X_all.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['price', 'starRating', 'category', 'totalNrOfReviews', 'installs',\n",
       "       'contentRating', 'libraries', 'bigCompany', 'daysSinceLastUpdated',\n",
       "       'text', '1starReviews', '2starReviews', '3starReviews', '4starReviews',\n",
       "       '5starReviews', 'requiredAndroidVersion_major',\n",
       "       'requiredAndroidVersion_minor'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['price', 'starRating']]\n",
    "\n",
    "data.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18576, 16) X_train\n",
      "(6192, 16) X_eval\n",
      "2 features dropped\n",
      "2 features dropped\n",
      "\n",
      "y_train value counts:\n",
      "2.0    5272\n",
      "1.0    5145\n",
      "4.0    4642\n",
      "3.0    3517\n",
      "Name: price, dtype: int64\n",
      "\n",
      "y_test value counts:\n",
      "2.0    1750\n",
      "1.0    1642\n",
      "4.0    1561\n",
      "3.0    1239\n",
      "Name: price, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "    ######################################\n",
    "    # Train / Test Split\n",
    "    #\n",
    "    X_train, X_eval, y_train, y_eval = train_test_split(X_all, y_all)\n",
    "\n",
    "    # just to be save\n",
    "    X_train = X_train.copy()\n",
    "    X_eval = X_eval.copy()\n",
    "    y_train = y_train.copy()\n",
    "    y_eval = y_eval.copy()\n",
    "\n",
    "    print(\"{0} X_train\".format(X_train.shape))\n",
    "    print(\"{0} X_eval\".format(X_eval.shape))\n",
    "\n",
    "\n",
    "\n",
    "    ######################################\n",
    "    # Preprocessing\n",
    "    #\n",
    "    cleanup.dropFeatures(X_train, ['text', 'category'])\n",
    "    cleanup.dropFeatures(X_eval, ['text', 'category'])\n",
    "\n",
    "    # calculate price quartiles manually\n",
    "    # cannot modify y with a custom transformer\n",
    "    prepare.price_quartiles_transform(y_train, y_eval)\n",
    "\n",
    "    # column encoder\n",
    "    column_encoder = prepare.encode(X_train.columns)\n",
    "\n",
    "\n",
    "\n",
    "    ######################################\n",
    "    # Model building\n",
    "    #\n",
    "    pipe_steps = [\n",
    "        ('encode', column_encoder),\n",
    "        ('gradient', GradientBoostingClassifier())\n",
    "    ]\n",
    "    pipeline = Pipeline(pipe_steps)\n",
    "\n",
    "    # here I need to add things\n",
    "\n",
    "\n",
    "\n",
    "    ######################################\n",
    "    # Model tuning\n",
    "    #\n",
    "    strat_3 = StratifiedKFold(n_splits=STRAT_SPLITS)\n",
    "\n",
    "    search = RSCV(estimator=pipeline,\n",
    "                  param_distributions={\n",
    "                      \"gradient__n_estimators\": sp_randint(80, 120),\n",
    "                      \"gradient__max_depth\": sp_randint(2, 7)\n",
    "                  },\n",
    "                  n_iter=SEARCH_ITER, scoring=SCORE, n_jobs=NJ, cv=strat_3)\n",
    "\n",
    "\n",
    "\n",
    "    ######################################\n",
    "    # Model fitting\n",
    "    #\n",
    "    search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "\n",
    "    ######################################\n",
    "    # Model prediction\n",
    "    #\n",
    "    y_pred = search.predict(X_eval)\n",
    "    y_proba = search.predict_proba(X_eval)\n",
    "    y_proba_pos = y_proba[:, 1]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encode__default                                            False\n",
      "encode__df_out                                             False\n",
      "encode__sparse                                             False\n",
      "encode__features_installs                       ['LabelEncoder']\n",
      "encode__features_contentRating                  ['LabelEncoder']\n",
      "step_1_name                                               encode\n",
      "step_1_est                                       DataFrameMapper\n",
      "encode__input_df                                           False\n",
      "gradient__n_estimators                                        97\n",
      "gradient__random_state                                      None\n",
      "gradient__criterion                                 friedman_mse\n",
      "gradient__max_features                                      None\n",
      "gradient__presort                                           auto\n",
      "gradient__loss                                          deviance\n",
      "gradient__max_depth                                            6\n",
      "gradient__min_samples_leaf                                     1\n",
      "gradient__min_impurity_decrease                              0.0\n",
      "gradient__min_weight_fraction_leaf                           0.0\n",
      "gradient__min_samples_split                                    2\n",
      "gradient__verbose                                              0\n",
      "gradient__warm_start                                       False\n",
      "gradient__init                                              None\n",
      "gradient__subsample                                          1.0\n",
      "gradient__learning_rate                                      0.1\n",
      "gradient__min_impurity_split                                None\n",
      "step_2_name                                             gradient\n",
      "step_2_est                            GradientBoostingClassifier\n",
      "gradient__max_leaf_nodes                                    None\n",
      "score_f1_weighted_train_mean                            0.692605\n",
      "score_f1_weighted_train_std                           0.00209653\n",
      "score_f1_weighted_test_mean                             0.352746\n",
      "score_f1_weighted_test_std                            0.00106473\n",
      "score_precision_eval_mean                               0.359434\n",
      "score_precision_eval_std                               0.0267363\n",
      "score_recall_eval_mean                                  0.350757\n",
      "score_recall_eval_std                                   0.143762\n",
      "score_f1_eval_mean                                      0.339819\n",
      "score_f1_eval_std                                       0.100885\n",
      "score_accuracy_eval                                     0.367248\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "######################################\n",
    "# Evaluate Model performance\n",
    "#\n",
    "rs = evaluate.onSearch(pd.Series(), search)\n",
    "evaluate.onMetrics(rs, y_eval, y_pred)\n",
    "print(rs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
