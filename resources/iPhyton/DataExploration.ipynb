{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 9694: expected 33 fields, saw 37\\nSkipping line 11178: expected 33 fields, saw 34\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28448, 33) \t after read_csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2683: DtypeWarning: Columns (5,7,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "requireAppBrainData = False\n",
    "bigCompanyThreshold = 10\n",
    "\n",
    "def dropRowsWithMissingFeature(data, feature, missingValue):\n",
    "    # consistency\n",
    "    data[feature] = data[feature].astype(float)\n",
    "    # easier handling\n",
    "    data.loc[data[feature] == missingValue, feature] = np.nan\n",
    "    # log\n",
    "    print(\"{0} \\t\\t\\t samples dropped due to missing {1}\".format(data[feature].isnull().sum(), feature))\n",
    "    # drop\n",
    "    data.dropna(subset=[feature], how='any', inplace=True)\n",
    "    # assert\n",
    "    assert data[feature].isnull().sum() == 0\n",
    "\n",
    "\n",
    "def dropFeatures(data, featureNames):\n",
    "    for feature in featureNames:\n",
    "        data.drop(feature, axis=1, inplace=True)\n",
    "\n",
    "    print(\"{0} \\t\\t\\t\\t features dropped\".format(len(featureNames)))\n",
    "\n",
    "\n",
    "def dropRowsWithErrorsUsingAppId(data, appIds):\n",
    "    for appId in appIds:\n",
    "        data.drop(data.loc[data.appId == appId, :].index, inplace=True)\n",
    "\n",
    "    print(\"{0} \\t\\t\\t\\t samples dropped due to problems with importing\".format(len(appIds)))\n",
    "\n",
    "\n",
    "data = pd.read_csv('data.csv', error_bad_lines=False)\n",
    "\n",
    "print(\"{0} \\t after read_csv\".format(data.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Oceanhouse Media, Inc.        177\n",
       "Big Fish Games                170\n",
       "Hit Songs Ringtones           137\n",
       "Awesome Ringtones             124\n",
       "GabySoft                      101\n",
       "SaintBerlin                    81\n",
       "Gluten Free Games              78\n",
       "WatchMaster                    78\n",
       "2Thumbz, Inc                   75\n",
       "The Fool's Dog                 71\n",
       "FLYTOMAP INC                   61\n",
       "Diviniti Publishing Ltd        60\n",
       "Monotype Imaging Inc.          60\n",
       "PuzzleBoss Inc                 58\n",
       "Nickelodeon                    57\n",
       "KEMCO                          57\n",
       "Smartwatch Bureaux             56\n",
       "Upward Mobility                55\n",
       "Authentic Ringtones            54\n",
       "Noodlecake Studios Inc         51\n",
       "Tecarta, Inc.                  50\n",
       "Ringtone App                   48\n",
       "Alawar Entertainment, Inc.     44\n",
       "Ringtone Lord                  44\n",
       "Artifex Mundi                  42\n",
       "Kairosoft Co.,Ltd              42\n",
       "Tapanifinal                    40\n",
       "Teoti Graphix, LLC             39\n",
       "memscape                       37\n",
       "Ruslan Sokolovsky              36\n",
       "                             ... \n",
       "Seamless Solutions LLC          1\n",
       "Acoustiguide Inc.               1\n",
       "GameDigits Ltd                  1\n",
       "Mellow                          1\n",
       "Pavel Alexeev                   1\n",
       "CHOBIN.net                      1\n",
       "Billion Hands Technology        1\n",
       "Vegan Scanner Worldwide         1\n",
       "Flinn Built                     1\n",
       "Squall Line Software, LLC       1\n",
       "Merge Soft Corp                 1\n",
       "Shakkilinna                     1\n",
       "Zadre Studios                   1\n",
       "Philymack Stickers              1\n",
       "Enso                            1\n",
       "CamelWeb Creations App Dev      1\n",
       "OnellDev                        1\n",
       "WizeTV                          1\n",
       "TECHNOINVEST GROUP              1\n",
       "ArkudaDigital                   1\n",
       "IKARUS Projects                 1\n",
       "ABT                             1\n",
       "Lakoo                           1\n",
       "SAMDROID                        1\n",
       "Muslime                         1\n",
       "Oideas Gael                     1\n",
       "Debra Games                     1\n",
       "Dan Gorman                      1\n",
       "Eric Intzandt                   1\n",
       "AZ Fachverlage AG               1\n",
       "Name: author, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.author.describe()\n",
    "\n",
    "data.author.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Value Summary:\n",
      "_id                               0\n",
      "appId                             0\n",
      "name                            322\n",
      "linkName                        322\n",
      "price                           322\n",
      "starRating                      322\n",
      "category                        325\n",
      "badge                         28420\n",
      "author                          322\n",
      "totalNrOfReviews                322\n",
      "reviewsPerStarRating            322\n",
      "description                     323\n",
      "whatsNew                       8530\n",
      "lastUpdated                     325\n",
      "size                          26766\n",
      "installs                        416\n",
      "currentVersion                  920\n",
      "requiredAndroidVersion          323\n",
      "contentRating                   323\n",
      "permissions                     348\n",
      "inAppProducts                 26480\n",
      "appUrl                          322\n",
      "similarApps                     323\n",
      "ranking                       11585\n",
      "binarySize                    11873\n",
      "libraries                      5241\n",
      "age                           11584\n",
      "commentsTag                    5240\n",
      "resourcePermissions            5240\n",
      "lastAppBrainCrawlTimestamp    11084\n",
      "lastAppInfoCrawlTimestamp      7985\n",
      "userComments                  12600\n",
      "offersInAppPurchases          26054\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "    print(\"Missing Value Summary:\")\n",
    "    print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 \t\t\t\t samples dropped due to problems with importing\n",
      "3 \t\t\t\t features dropped\n",
      "17 \t\t\t\t features dropped\n"
     ]
    }
   ],
   "source": [
    "    #\n",
    "    #\n",
    "    # DATA SELECTION\n",
    "    #\n",
    "\n",
    "    dropRowsWithErrorsUsingAppId(data, [\n",
    "        # contains problem causing name \"/ ESCAPE \\\"\n",
    "        'air.com.kongregate.mobile.games.incredibleape.escape',\n",
    "        # contains problem with installs (1.0.8 or 1.0) - again some export/read_csv problem\n",
    "        'com.dotemu.thelastexpress',\n",
    "        'rogerfgm.frameextractorex',\n",
    "        # too many missing values\n",
    "        'com.maiko.xscanpet'\n",
    "    ])\n",
    "\n",
    "\n",
    "    # drop rows with incomplete info from AppBrain\n",
    "    #\n",
    "    if requireAppBrainData:\n",
    "        # drop rows which have no binarySize information\n",
    "        # TODO: report how many\n",
    "        data.dropna(subset=['binarySize'], how='any', inplace=True)\n",
    "    else:\n",
    "        # drop non-text features\n",
    "        dropFeatures(data, [\n",
    "            'ranking',\n",
    "            'binarySize',\n",
    "            'age'\n",
    "        ])\n",
    "\n",
    "\n",
    "    dropFeatures(data, [\n",
    "        '_id',\n",
    "        'lastAppInfoCrawlTimestamp',\n",
    "        'appId',\n",
    "        'name',\n",
    "        'linkName',\n",
    "        'badge',\n",
    "        'size',\n",
    "        'appUrl',\n",
    "        'similarApps',\n",
    "        'userComments',\n",
    "        'commentsTag',\n",
    "        'lastAppBrainCrawlTimestamp',\n",
    "        'currentVersion',\n",
    "        # TODO: inAppPurchase dropping: too much missing at this point\n",
    "        'inAppProducts',\n",
    "        'offersInAppPurchases',\n",
    "        # TODO: 'permissions' & 'resourcePermissions', must be categorical or how many permissions\n",
    "        'permissions',\n",
    "        'resourcePermissions'\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "415 \t\t\t samples dropped due to missing price\n",
      "3261 \t\t\t samples dropped due to missing starRating\n",
      "0 \t\t\t samples dropped due to missing totalNrOfReviews\n"
     ]
    }
   ],
   "source": [
    "    #\n",
    "    #\n",
    "    # DATA CLEANING & FEATURE EXTRACTION\n",
    "    #\n",
    "\n",
    "    # price: drop rows with missing\n",
    "    #\n",
    "    dropRowsWithMissingFeature(data, 'price', 0.0)\n",
    "\n",
    "\n",
    "    # text features: concat\n",
    "    #\n",
    "    TEXT_FEATURES = ['description', 'whatsNew']\n",
    "\n",
    "    data['text'] = data.loc[:, TEXT_FEATURES].apply(lambda x: ' '.join(map(str, x)), axis=1)\n",
    "    data.drop(TEXT_FEATURES, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    # author: extract bigCompany\n",
    "    #\n",
    "    author_counts = data['author'].value_counts()\n",
    "    bigCompanies = author_counts[author_counts > bigCompanyThreshold]\n",
    "\n",
    "    data['bigCompany'] = data['author'].apply(lambda x: 1.0 if x in bigCompanies else 0.0)\n",
    "    data.drop('author', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    # starRating: drop rows with missing\n",
    "    #\n",
    "    dropRowsWithMissingFeature(data, 'starRating', 0.0)\n",
    "\n",
    "\n",
    "    # totalNrOfReviews: drop rows with missing\n",
    "    #\n",
    "    dropRowsWithMissingFeature(data, 'totalNrOfReviews', 0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    # reviewsPerStarRating: make 5 separate features\n",
    "    #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21 \t\t\t\t missing 'installs' replaced with their top value '100 - 500'\n",
      "1588 \t\t\t missing 'requiredAndroidVersion' replaced with their top value '4.0'\n",
      "0 \t\t\t\t missing 'contentRating' replaced with 'Unrated'\n",
      "3902 \t\t\t missing 'libraries' replaced with their median '0.0'\n"
     ]
    }
   ],
   "source": [
    "    # lastUpdated: transform into days since lastUpdated\n",
    "    #\n",
    "    data['days_since_lastUpdated'] = data['lastUpdated']\\\n",
    "        .apply(lambda x: (datetime.now() - datetime.strptime(str(x), '%B %d, %Y')).days).astype(float)\n",
    "\n",
    "    data.drop('lastUpdated', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    # installs: transform into 14 unique categories\n",
    "    #\n",
    "    # Handle missing values first\n",
    "    # TODO: pipeline for imputing\n",
    "    installsTop = data['installs'].describe().loc['top']\n",
    "\n",
    "    print(\"{0} \\t\\t\\t\\t missing 'installs' replaced with their top value '{1}'\".format(data['installs'].isnull().sum(), installsTop))\n",
    "\n",
    "    data.loc[data['installs'].isnull(), 'installs'] = installsTop\n",
    "    assert data['installs'].isnull().sum() == 0\n",
    "\n",
    "\n",
    "    # requiredAndroidVersion: create two features representing the major and minor version\n",
    "    #\n",
    "    # Handle missing values first\n",
    "    # TODO: pipeline for imputing\n",
    "    versionTop = data['requiredAndroidVersion'].str.extractall('^(\\d.\\d)').describe().loc['top', 0]\n",
    "\n",
    "    data.loc[data['requiredAndroidVersion'] == 'Varies with device', 'requiredAndroidVersion'] = np.nan\n",
    "\n",
    "    print(\"{0} \\t\\t\\t missing 'requiredAndroidVersion' replaced with their top value '{1}'\".format(data['requiredAndroidVersion'].isnull().sum(), versionTop))\n",
    "\n",
    "    data.loc[data['requiredAndroidVersion'].isnull(), 'requiredAndroidVersion'] = versionTop\n",
    "    assert data['requiredAndroidVersion'].isnull().sum() == 0\n",
    "\n",
    "    # Now we can parse out the numbers\n",
    "    data['requiredAndroidVersion_major'] = \\\n",
    "        data['requiredAndroidVersion'].apply(lambda x: re.search(r'^(\\d).\\d', x).group(1)).astype(float)\n",
    "    data['requiredAndroidVersion_minor'] = \\\n",
    "        data['requiredAndroidVersion'].apply(lambda x: re.search(r'^\\d.(\\d)', x).group(1)).astype(float)\n",
    "\n",
    "    data.drop('requiredAndroidVersion', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    # contentRating: transform into 5 unique categories\n",
    "    #\n",
    "    # Since we're categorizing later we need to handle missing values first\n",
    "    # TODO: pipeline for imputing\n",
    "    missingRating = 'Unrated'\n",
    "\n",
    "    print(\"{0} \\t\\t\\t\\t missing 'contentRating' replaced with '{1}'\".format(data['contentRating'].isnull().sum(), missingRating))\n",
    "\n",
    "    data.loc[data['contentRating'].isnull(), 'contentRating'] = missingRating\n",
    "    assert data['contentRating'].isnull().sum() == 0\n",
    "\n",
    "\n",
    "    # libraries: fill missing with 0\n",
    "    #\n",
    "    # TODO: pipeline for imputing\n",
    "    librariesMedian = data.loc[data['libraries'].notnull(), ['libraries']].median()[0].astype(float)\n",
    "\n",
    "    print(\"{0} \\t\\t\\t missing 'libraries' replaced with their median '{1}'\".format(data['libraries'].isnull().sum(), librariesMedian))\n",
    "\n",
    "    data.loc[data['libraries'].isnull(), 'libraries'] = str(librariesMedian)\n",
    "    assert data['libraries'].isnull().sum() == 0\n",
    "\n",
    "    data['libraries'] = data['libraries'].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price                           0\n",
       "starRating                      0\n",
       "category                        0\n",
       "totalNrOfReviews                0\n",
       "reviewsPerStarRating            0\n",
       "installs                        0\n",
       "contentRating                   0\n",
       "libraries                       0\n",
       "text                            0\n",
       "bigCompany                      0\n",
       "days_since_lastUpdated          0\n",
       "requiredAndroidVersion_major    0\n",
       "requiredAndroidVersion_minor    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is what still has to be worked on\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t\t\t\t missing 'category' replaced with their top value 'PERSONALIZATION'\n"
     ]
    }
   ],
   "source": [
    "    # category: just cleanup\n",
    "    #\n",
    "    # TODO: pipeline for imputing\n",
    "    data['category'] = data['category'].str.upper()\n",
    "    categoryTop = data['category'].describe().loc['top']\n",
    "\n",
    "    print(\"{0} \\t\\t\\t\\t missing 'category' replaced with their top value '{1}'\".format(data['category'].isnull().sum(), categoryTop))\n",
    "\n",
    "    data.loc[data['category'].isnull(), 'category'] = categoryTop\n",
    "    assert data['category'].isnull().sum() == 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PERSONALIZATION'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data['category'] == 1, ['category']]\n",
    "data.describe()\n",
    "data.loc[data['category'].isnull(),:]\n",
    "\n",
    "data['category'].describe().loc['top']\n",
    "\n",
    "data.category.unique()\n",
    "\n",
    "data.category.value_counts()\n",
    "data.category.describe()\n",
    "data.loc[data['category'] == '[{\"1\":0},{\"2\":0},{\"3\":0},{\"4\":0},{\"5\":0}]',:].index\n",
    "\n",
    "data.loc[data.category.isnull(), :]\n",
    "data['category'].describe().loc['top']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24768, 13) \t done cleaning\n",
      "Missing Value Summary:\n",
      "price                           0\n",
      "starRating                      0\n",
      "category                        0\n",
      "totalNrOfReviews                0\n",
      "reviewsPerStarRating            0\n",
      "installs                        0\n",
      "contentRating                   0\n",
      "libraries                       0\n",
      "text                            0\n",
      "bigCompany                      0\n",
      "days_since_lastUpdated          0\n",
      "requiredAndroidVersion_major    0\n",
      "requiredAndroidVersion_minor    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "    print(\"{0} \\t done cleaning\".format(data.shape))\n",
    "\n",
    "    print(\"Missing Value Summary:\")\n",
    "    print(data.isnull().sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
